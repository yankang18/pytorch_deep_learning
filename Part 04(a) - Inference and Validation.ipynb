{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Validation\n",
    "\n",
    "Now that you have a trained network, you can use it for making predictions. This is typically called **inference**, a term borrowed from statistics. However, neural networks have a tendency to perform *too well* on the training data and are not able to generalize to data that has not been seen before. This is called **overfitting** and it impairs inference performance. To test for overfitting while training, we measure the performance on data not in the training set called the **validation** dataset. We avoid overfitting through regularization such as dropout while monitoring the validation performance during training. In this notebook, I'll show you how to do this in PyTorch. \n",
    "\n",
    "First off, I'll implement my own feedforward network for the exercise you worked on in part 4 using the Fashion-MNIST dataset.\n",
    "\n",
    "As usual, let's start by loading the dataset through torchvision. You'll learn more about torchvision and loading data in a later part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Create data loader\n",
    "\n",
    "1. Create **train_set** and **test_set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in train_set:60000\n",
      "number of samples in test_set:10000\n"
     ]
    }
   ],
   "source": [
    "# Define batch size\n",
    "batch_size = 64\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "train_set = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "test_set = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "n_train_set = len(train_set)\n",
    "n_test_set = len(test_set)\n",
    "print(\"number of samples in train_set:{0}\".format(n_train_set))\n",
    "print(\"number of samples in test_set:{0}\".format(n_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split original **test_set** into **test_set** and **val_set** (validate set) using [torch.utils.data.random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in val_set:5000\n",
      "number of samples in test_set:5000\n"
     ]
    }
   ],
   "source": [
    "n_val_set = int(n_test_set/2)\n",
    "n_test_set = n_test_set - n_val_set\n",
    "\n",
    "# Randomly split the test_set into test_set and val_set\n",
    "test_set, val_set = torch.utils.data.random_split(test_set, [n_test_set, n_val_set])\n",
    "\n",
    "n_val_set = len(val_set)\n",
    "n_test_set = len(test_set)\n",
    "print(\"number of samples in val_set:{0}\".format(n_val_set))\n",
    "print(\"number of samples in test_set:{0}\".format(n_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create **trainloader**, **validateloader** and **testloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validateloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building the network\n",
    "\n",
    "As with MNIST, each image in Fashion-MNIST is 28x28 which is a total of 784 pixels, and there are 10 classes. I'm going to get a bit more advanced here, I want to be able to build a network with an arbitrary number of hidden layers. That is, I want to pass in a parameter like `hidden_layers = [512, 256, 128]` and the network is contructed with three hidden layers have 512, 256, and 128 units respectively. To do this, I'll use `nn.ModuleList` to allow for an arbitrary number of hidden layers. \n",
    "\n",
    "> Using `nn.ModuleList` works pretty much the same as a normal Python list, except that it registers each hidden layer (e.g., `Linear`) module properly so the model is aware of the layers.\n",
    "\n",
    "The issue here is I need a way to define each `nn.Linear` module with the appropriate layer sizes. Since each `nn.Linear` operation needs an input size and an output size, I need something that looks like this:\n",
    "\n",
    "```python\n",
    "# Create ModuleList and add input layer\n",
    "hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "# Add hidden layers to the ModuleList\n",
    "hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "```\n",
    "\n",
    "Getting these pairs of input and output sizes can be done with a handy trick using `zip`.\n",
    "\n",
    "```python\n",
    "hidden_layers = [512, 256, 128, 64]\n",
    "layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "for each in layer_sizes:\n",
    "    print(each)\n",
    "\n",
    ">> (512, 256)\n",
    ">> (256, 128)\n",
    ">> (128, 64)\n",
    "```\n",
    "\n",
    "I also have the `forward` method returning the log-softmax for the output. Since softmax is a probability distibution over the classes, the log-softmax is a log probability which comes with a [lot of benefits](https://en.wikipedia.org/wiki/Log_probability). Using the log probability, computations are often faster and more accurate. To get the class probabilities later, I'll need to take the exponential (`torch.exp`) of the output. Algebra refresher... the exponential function is the inverse of the log function:\n",
    "\n",
    "$$ \\large{e^{\\ln{x}} = x }$$\n",
    "\n",
    "We can include dropout in our network with [`nn.Dropout`](http://pytorch.org/docs/master/nn.html#dropout), [source code](https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/dropout.py). This works similar to other modules such as `nn.Linear`. It also takes the dropout probability as an input which we can pass as an input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            drop_p: float between 0 and 1, dropout probability\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the first layer, input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Define a variable number of hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        # Define output layer\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        # Define dropout layer\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        # Forward through each layer in `hidden_layers`, with ReLU activation and dropout\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Since the model's forward method returns the log-softmax, I used the [negative log loss](http://pytorch.org/docs/master/nn.html#nllloss) as my loss function, `nn.NLLLoss(input, target)`. \n",
    "\n",
    "* The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
    "* Obtaining log-probabilities in a neural network is easily achieved by adding a LogSoftmax layer `nn.LogSoftmax()` in the last layer of your network. You may use CrossEntropyLoss instead, if you prefer not to add an extra layer.\n",
    "* The `input` given through a forward call is expected to contain log-probabilities of each class. input has to be a Tensor of size either (minibatch,C) or (minibatch,C,d1,d2,...,dK) with K≥2 for the K-dimensional case (described later).\n",
    "* The `target` that this loss expects is a class index (0 to C-1, where C = number of classes)\n",
    "\n",
    "I also chose to use the [Adam optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Adam). This is a variant of stochastic gradient descent which includes momentum and in general trains faster than your basic SGD.\n",
    "\n",
    "I've also included a block to measure the validation loss and accuracy. Since I'm using dropout in the network, I need to turn it off during inference. Otherwise, the network will appear to perform poorly because many of the connections are turned off. \n",
    "\n",
    "> PyTorch allows you to set a model in \"training\" or \"evaluation\" modes with `model.train()` and `model.eval()`, respectively. In training mode, dropout is turned on, while in evaluation mode, dropout is turned off. This affects other modules (e.g., batch normalization) as well that should be on during training but off during inference.\n",
    "\n",
    "The validation code consists of a forward pass through the validation set (also split into batches). With the log-softmax output, I calculate the loss on the validation set, as well as the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=516, bias=True)\n",
      "    (1): Linear(in_features=516, out_features=256, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "model = Network(784, 10, [516, 256], drop_p=0.5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, testloader):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += loss_func(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1..  Training Loss: 1.333..  Test Loss: 0.769..  Validation Accuracy: 0.729\n",
      "Epoch: 1/1..  Training Loss: 0.827..  Test Loss: 0.633..  Validation Accuracy: 0.760\n",
      "Epoch: 1/1..  Training Loss: 0.744..  Test Loss: 0.605..  Validation Accuracy: 0.780\n",
      "Epoch: 1/1..  Training Loss: 0.669..  Test Loss: 0.594..  Validation Accuracy: 0.775\n",
      "Epoch: 1/1..  Training Loss: 0.672..  Test Loss: 0.536..  Validation Accuracy: 0.809\n",
      "Epoch: 1/1..  Training Loss: 0.645..  Test Loss: 0.580..  Validation Accuracy: 0.794\n",
      "Epoch: 1/1..  Training Loss: 0.615..  Test Loss: 0.531..  Validation Accuracy: 0.808\n",
      "Epoch: 1/1..  Training Loss: 0.626..  Test Loss: 0.525..  Validation Accuracy: 0.811\n",
      "Epoch: 1/1..  Training Loss: 0.579..  Test Loss: 0.491..  Validation Accuracy: 0.821\n",
      "Epoch: 1/1..  Training Loss: 0.561..  Test Loss: 0.503..  Validation Accuracy: 0.821\n",
      "Epoch: 1/1..  Training Loss: 0.560..  Test Loss: 0.512..  Validation Accuracy: 0.811\n",
      "Epoch: 1/1..  Training Loss: 0.571..  Test Loss: 0.490..  Validation Accuracy: 0.819\n",
      "Epoch: 1/1..  Training Loss: 0.538..  Test Loss: 0.491..  Validation Accuracy: 0.821\n",
      "Epoch: 1/1..  Training Loss: 0.520..  Test Loss: 0.478..  Validation Accuracy: 0.829\n",
      "Epoch: 1/1..  Training Loss: 0.514..  Test Loss: 0.490..  Validation Accuracy: 0.827\n",
      "Epoch: 1/1..  Training Loss: 0.536..  Test Loss: 0.474..  Validation Accuracy: 0.831\n",
      "Epoch: 1/1..  Training Loss: 0.540..  Test Loss: 0.471..  Validation Accuracy: 0.830\n",
      "Epoch: 1/1..  Training Loss: 0.518..  Test Loss: 0.480..  Validation Accuracy: 0.819\n",
      "Epoch: 1/1..  Training Loss: 0.557..  Test Loss: 0.459..  Validation Accuracy: 0.833\n",
      "Epoch: 1/1..  Training Loss: 0.519..  Test Loss: 0.476..  Validation Accuracy: 0.831\n",
      "Epoch: 1/1..  Training Loss: 0.511..  Test Loss: 0.465..  Validation Accuracy: 0.831\n",
      "Epoch: 1/1..  Training Loss: 0.518..  Test Loss: 0.462..  Validation Accuracy: 0.835\n",
      "Epoch: 1/1..  Training Loss: 0.517..  Test Loss: 0.446..  Validation Accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        # Flatten images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "#         print(\"output shape {0}\".format(output.shape))\n",
    "#         print(\"output shape {0}\".format(labels.shape))\n",
    "        loss = loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # Make sure network is in eval mode for inference\n",
    "            model.eval()\n",
    "            \n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, validateloader)\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Validation Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            # Make sure training is back on\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two important functions for validation and inference, **model.eval()** and **torch.no_grad()**:\n",
    "* **model.eval()** will notify all layers of the model that you are in eval mode such that layers such as batchnorm and dropout will work in eval mode instead of training mode. A model in PyTorch has two states `eval()` and `train()`. The difference between the states is rooted in stateful layers like Batch Norm (Batch statistics in training vs population statistics in inference) and Dropout which behave different during inference and training. `eval()` tells the `nn.Module` to put these layers in inference mode, while `train()` tells `nn.Module` to put it in the training mode.\n",
    "* **torch.no_grad()** impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that the model is trained, we can use it for inference. We've done this before, but now we need to remember to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 204,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test out your network!\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up!\n",
    "\n",
    "In the next part, I'll show you how to save your trained models. In general, you won't want to train a model everytime you need it. Instead, you'll train once, save it, then load the model when you want to train more or use if for inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
