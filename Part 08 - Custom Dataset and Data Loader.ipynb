{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset and Data Loader\n",
    "\n",
    "This document is basically copied from [pytorch-101-building-neural-networks](https://blog.paperspace.com/pytorch-101-building-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using following two commands to download cifar-10 dataset.\n",
    "\n",
    "```python\n",
    "wget http://pjreddie.com/media/files/cifar.tgz\n",
    "tar xzf cifar.tgz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import time\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"../data/cifar/train\"\n",
    "test_data_dir = \"../data/cifar/test\"\n",
    "label_data_dir = \"../data/cifar/labels.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read the labels of the classes present in the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "with open(label_data_dir) as label_file:\n",
    "    labels = label_file.read().split()\n",
    "    label_mapping = dict(zip(labels, list(range(len(labels)))))\n",
    "\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Format\n",
    "\n",
    "The type of data we are dealing with will dictate what input we use. Generally, in PyTorch, batch is always the first dimension. Since we are dealing with Images here, I will describe the input format required by images.  \n",
    "\n",
    "The input format for images is `[B C H W]`. Where `B` is the batch size, `C` are the channels, `H` is the height and `W` is the width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be reading images using `PIL` library. Before we write the functionality to load our data, we write a preprocessing function that does the following things.\n",
    "\n",
    "1. Randomly flip the image upside-down with a probability of 0.5\n",
    "2. Normalise the image with mean and standard deviation of CIFAR dataset\n",
    "3. Reshape it from `W  H  C` to `C  H  W`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = np.array(image)\n",
    "    \n",
    "    if random.random() > 0.5:\n",
    "        image = image[::-1,:,:]\n",
    "    \n",
    "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
    "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
    "    image = (image - cifar_mean) / cifar_std\n",
    "    \n",
    "    image = image.transpose(2,1,0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, there are two classes PyTorch provides you in relation to build input pipelines to load data.\n",
    "\n",
    "1. `torch.data.utils.dataset`, which we will just refer as the dataset class now.\n",
    "2. `torch.data.utils.dataloader` , which we will just refer as the dataloader class now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.utils.data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset` is a class that loads the data and returns a generator so that you iterate over it. It also lets you incorporate data augmentation techniques into the input Pipeline.\n",
    "\n",
    "If you want to create a `dataset` object for your data, you need to overload three functions.\n",
    "\n",
    "1. `__init__` function. Here, you define things related to your dataset here. Most importantly, the location of your data. You can also define various data augmentations you want to apply.\n",
    "2. `__len__` function. Here, you just return the length of the dataset.\n",
    "3. `__getitem__` function. The function takes as an argument an index `i` and returns a data example. This function would be called every iteration during our training loop with a different `i` by the `dataset` object.\n",
    "\n",
    "Here is a implementation of our `dataset` object for the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, data_size=0, transforms=None):\n",
    "        files = os.listdir(data_dir)\n",
    "        files = [os.path.join(data_dir, x) for x in files]\n",
    "        \n",
    "        if data_size < 0 or data_size > len(files):\n",
    "            raise Exception(\"Data size should be between 0 and {0}\".format(len(files)))\n",
    "            \n",
    "        if data_size == 0:\n",
    "            data_size = len(files)\n",
    "            \n",
    "        self.data_size = data_size\n",
    "        self.files = random.sample(files, self.data_size)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_address = self.files[index]\n",
    "        image = Image.open(image_address)\n",
    "        image = preprocess(image)\n",
    "        label_name = image_address[:-4].split(\"_\")[-1]\n",
    "        label = label_mapping[label_name]\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use the `__getitem__` function to extract the label for an image encoded in its file name.  \n",
    "\n",
    "`Dataset` class allows us to incorporate the `lazy data loading` principle. This means instead of loading all data at once into the memory (which could be done by loading all the images in memory in the `__init__` function rather than just image addresses), it only loads a data example whenever it is needed (when `__getitem__ `is called).\n",
    "\n",
    "When you create an object of the `Dataset` class, you basically can iterate over the object as you would over any python iterable. Each iteration, `__getitem__` with the incremented index `i` as its input argument.\n",
    "\n",
    "I've passed a `transforms`  argument in the `__init__` function as well. This can be any python function that does data augmentation. While you can do the data augmentation right inside your preprocess code, doing it inside the `__getitem__` is just a matter of taste. There are a plethora of data augmentation libraries that can be used to augment data. For our case, we use `torchvision` library, which provides a lot of pre-built transforms along with the ability to compose them into one bigger transform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.utils.data.Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataloader` class facilitates\n",
    "1. Batching of Data\n",
    "2. Shuffling of Data\n",
    "3. Loading multiple data at a single time using threads\n",
    "4. Prefetching, that is, while GPU crunches the current batch, `Dataloader` can load the next batch into memory in meantime. This means GPU doesn't have to wait for the next batch and it speeds up training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a `Dataloader` object with a `Dataset` object. Then, we can iterate over a `Dataloader` object instance just like we did with a `dataset` instance. In addition, we can specify various options (such that `batch size`, `shuffle` and `num_workers`) for controling the looping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Cifar10Dataset(data_dir = train_data_dir, data_size=500, transforms=None)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testset = Cifar10Dataset(data_dir = test_data_dir, data_size=500, transforms=None)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the `trainset` and `trainloader` objects are python generator objects which can be iterated over in the following fashion.\n",
    "\n",
    "```python\n",
    "for data in trainloader:   # or trainset\n",
    "\timg, label = data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the `Dataloader` class makes things much more convenient than `Dataset` class.  While on each iteration the `Dataset` class would only return us the output of the `__getitem__` function, `Dataloader` does much more than that:\n",
    "\n",
    "1. Notice that the `__getitem__` method of `Cifar10Dataset` class returns a numpy array of shape `3 x 32 x 32`. `Dataloader` batches the images into Tensor of shape `B x 3 x 32 x 32`, where `B` is the batch size specfied by `batch_size`.\n",
    "2. Also notice that while `__getitem__` method outputs a numpy array, `Dataloader` class automatically converts it into a Tensor\n",
    "3. Even if the `__getitem__` method returns a object which is of non-numerical type, the `Dataloader` class turns it into a list/tuple of size `B`.  Suppose that  `__getitem__` return a string, namely the label string. If we set batch = 128 while instantiating the dataloader, each iteration, Dataloader will give us a tuple of 128 strings.\n",
    "\n",
    "Add prefetching, multiple threaded loading to above benefits, using `Dataloader` class is preferred almost every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the image sample with index:0, image shape:torch.Size([128, 3, 32, 32]), and label shape:torch.Size([128])\n",
      "the image sample with index:1, image shape:torch.Size([128, 3, 32, 32]), and label shape:torch.Size([128])\n",
      "the image sample with index:2, image shape:torch.Size([128, 3, 32, 32]), and label shape:torch.Size([128])\n",
      "the image sample with index:3, image shape:torch.Size([116, 3, 32, 32]), and label shape:torch.Size([116])\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(trainloader):   \n",
    "    img, label = data\n",
    "    print(\"the image sample with index:{0}, image shape:{1}, and label shape:{2}\".format(idx, img.shape, label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
